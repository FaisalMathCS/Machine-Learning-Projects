{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-1 (KNN Classifier)--PartB\n",
    "## Breast cancer wisconsin dataset\n",
    "In this assignment, we will build a KNN classifier that takes an features as as input and outputs a label 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The breast cancer dataset contains 569 samples with 30 real, positive features (including cancer mass attributes like mean radius, mean texture, mean perimeter, et cetera). Of the samples, 212 are labeled “malignant” and 357 are labeled “benign”. \n",
    "You can find more details in: https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "import time\n",
    "## Load the training set\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples:  569\n",
      "number of features 30\n",
      "the number of classes:  2\n",
      "the number of samples in the first class:  357\n",
      "the number of samples in the second class:  212\n"
     ]
    }
   ],
   "source": [
    "## print some statistics on the dataset\n",
    "### TODO YOUR CODE ###\n",
    "\n",
    "print(\"Total number of samples: \", len(X))\n",
    "\n",
    "# print the number of features per sample\n",
    "print(\"number of features\", np.shape(X)[1])\n",
    "\n",
    "\n",
    "# Total number of classes\n",
    "print(\"the number of classes: \", len(np.unique(y)))\n",
    "\n",
    "\n",
    "\n",
    "# print the number of samples in each class\n",
    "# print(y)\n",
    "positive = sum(y)\n",
    "negative = len(y) - positive\n",
    "print(\"the number of samples in the first class: \", positive)\n",
    "print(\"the number of samples in the second class: \", negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Train data to Train and Validate Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "### TODO YOUR CODE ###\n",
    "\n",
    "# Split the data (i.e. features and target) into 70% train, 15% validate, and 15% test; Use Random Seed 777\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=777)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=777)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbor classification with L2 distance\n",
    "\n",
    "To compute nearest neighbors in our data set, we need to first be able to compute distances between data points. A natural distance function is _Euclidean distance_: for two vectors $x, y \\in \\mathbb{R}^d$, their Euclidean distance is defined as \n",
    "$$\\|x - y\\| = \\sqrt{\\sum_{i=1}^d (x_i - y_i)^2}.$$\n",
    "Often we omit the square root, and simply compute _squared Euclidean distance_:\n",
    "$$\\|x - y\\|^2 = \\sum_{i=1}^d (x_i - y_i)^2.$$\n",
    "For the purposes of nearest neighbor computations, the two are equivalent: for three vectors $x, y, z \\in \\mathbb{R}^d$, we have $\\|x - y\\| \\leq \\|x - z\\|$ if and only if $\\|x - y\\|^2 \\leq \\|x - z\\|^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Nearest neighbor classification with L2 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **NN_L2**, which takes as input the training data (`trainx` and `trainy`) and the test points (`evalx`) and predicts labels for these test points using 1-NN classification. These labels should be returned in a `numpy` array with one entry per test point. For **NN_L2**, the L2 norm should be used as the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_L2(trainx, trainy, evalx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    ### START CODE HERE ###\n",
    "    predictions = []\n",
    "    \n",
    "    for eval_point in evalx:\n",
    "        distances = np.sqrt(np.sum((trainx - eval_point) ** 2, axis=1))\n",
    "        nearest_neighbor_index = np.argmin(distances)\n",
    "        predicted_label = trainy[nearest_neighbor_index]\n",
    "        \n",
    "        predictions.append(predicted_label)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "    \n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Nearest neighbor classification with L2 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN_L2**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), and the value of **K** (integer) and predicts labels for these test points using K-NN classification. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_L2(trainx, trainy, evalx, K):\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    for eval_point in evalx:\n",
    "        distances = np.sqrt(np.sum((trainx - eval_point) ** 2, axis=1))\n",
    "        \n",
    "        nearest_neighbor_indices = np.argsort(distances)[:k]\n",
    "        \n",
    "        nearest_neighbor_labels = trainy[nearest_neighbor_indices]\n",
    "        \n",
    "        predicted_label = np.argmax(np.bincount(nearest_neighbor_labels))\n",
    "        \n",
    "        predictions.append(predicted_label)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Nearest neighbor classification with L1 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute nearest neighbors using the L1 distance (sometimes called *Manhattan Distance*).\n",
    "\n",
    "Write a function, **NN_L1**, which again takes as input the arrays `trainx`, `trainy`, and `evalx`, and predicts labels for the test points using 1-nearest neighbor classification. For **NN_L1**, the L1 distance metric should be used. As before, the predicted labels should be returned in a `numpy` array with one entry per test point.\n",
    "\n",
    "Notice that **NN_L1** and **NN_L2** may well produce different predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_L1(trainx, trainy, evalx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    predictions = []\n",
    "    \n",
    "    for eval_point in evalx:\n",
    "          distances = np.sum(np.abs(trainx - eval_point), axis=1)\n",
    "        \n",
    "        nearest_neighbor_index = np.argmin(distances)\n",
    "        \n",
    "        predicted_label = trainy[nearest_neighbor_index]\n",
    "        \n",
    "        predictions.append(predicted_label)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Nearest neighbor classification with L1 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN_L1**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), and the value of **K** (integer) and predicts labels for these test points using K-NN classification and L1 distance metric. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_L1(trainx, trainy, evalx, K):\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    predictions = []\n",
    "    \n",
    "    for eval_point in evalx:\n",
    "        distances = np.sum(np.abs(trainx - eval_point), axis=1)\n",
    "        \n",
    "        nearest_neighbor_indices = np.argsort(distances)[:K]\n",
    "        \n",
    "        nearest_neighbor_labels = trainy[nearest_neighbor_indices]\n",
    "        \n",
    "        predicted_label = np.argmax(np.bincount(nearest_neighbor_labels))\n",
    "        \n",
    "        predictions.append(predicted_label)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-Nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), the value of **K** (integer), and a parameter for deciding the distance metric to be used (for example 1 for L1 and 2 for L2) and predicts labels for these test points using KNN classification. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(trainx, trainy, evalx, K, dist_metric=2):\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    if dist_metric == 1:\n",
    "        return KNN_L1(trainx, trainy, evalx, K)\n",
    "    elif dist_metric == 2:\n",
    "        return KNN_L2(trainx, trainy, evalx, K)\n",
    "    else:\n",
    "        print(\"worng value chose either 1, or 2\")\n",
    "\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code that allows you to select the hyper-parameters (distance measure and the value of K) by calling the KNN classifier with different values of K and either L1 or L2 distance measure. Make sure that you set the hyper-parameters using the validation set and not the test set. You need to systemtically try different values for K in conjunction with a distance measure and tabulate the results (you can do that be craeting a seperate cell and documenting in that cell) and note down the best hyper-parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "def accuracy(y_pred, valy):\n",
    "    if len(y_pred) != len(valy):\n",
    "        print(\"Error, different Sizes!\")\n",
    "        return None\n",
    "    correct = np.sum(y_pred == valy)\n",
    "    accuracy = correct / len(y_pred)\n",
    "    return accuracy\n",
    "L1acc = []\n",
    "L2acc = []\n",
    "Ks = [k for k in range(1, 26) if k % 2 != 0]\n",
    "for k in Ks: \n",
    "    y_predL1 = KNN(X_train, y_train, X_val,k , dist_metric=1)\n",
    "    y_predL2 = KNN(X_train, y_train, X_val, k)\n",
    "    L1acc.append(accuracy(y_predL1, y_val))\n",
    "    L2acc.append(accuracy(y_predL2, y_val))\n",
    "    \n",
    "best_acc_L1 = max(L1acc)\n",
    "best_acc_L2 = max(L2acc)\n",
    "best_K_L1 = Ks[L1acc.index(best_acc_L1)]\n",
    "best_K_L2 = Ks[L2acc.index(best_acc_L2)]\n",
    "# X_train, X_temp, y_train, y_temp \n",
    "\n",
    "# X_val, X_test, y_val, y_test \n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.9176470588235294, 3: 0.9176470588235294, 5: 0.9529411764705882, 7: 0.9411764705882353, 9: 0.9176470588235294, 11: 0.9176470588235294, 13: 0.9176470588235294, 15: 0.9176470588235294, 17: 0.8941176470588236, 19: 0.9058823529411765, 21: 0.9058823529411765, 23: 0.8941176470588236, 25: 0.8941176470588236}\n",
      "{1: 0.8941176470588236, 3: 0.9411764705882353, 5: 0.9294117647058824, 7: 0.9294117647058824, 9: 0.9176470588235294, 11: 0.9176470588235294, 13: 0.9058823529411765, 15: 0.9176470588235294, 17: 0.9058823529411765, 19: 0.8823529411764706, 21: 0.8823529411764706, 23: 0.8941176470588236, 25: 0.8941176470588236}\n",
      "the best accuracy along withe the K for the L1 metric 0.9529411764705882 and 5\n",
      "the best accuracy along withe the K for the L2 metric 0.9411764705882353 and 3\n",
      "we will be using L1 with K = 5\n"
     ]
    }
   ],
   "source": [
    "print(dict(zip(Ks, L1acc)))\n",
    "print(dict(zip(Ks, L2acc)))\n",
    "\n",
    "print(\"the best accuracy along withe the K for the L1 metric\", best_acc_L1,\"and\",  best_K_L1)\n",
    "print(\"the best accuracy along withe the K for the L2 metric\", best_acc_L2,\"and\",  best_K_L2)\n",
    "print(\"we will be using L1 with K = 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Test errors and the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the hyper-parameters have been selected, we now would like to perform a final evaluation on the test set and record the error rates. Also, Write a function, **confusion**, which takes as input the true labels for the test set (that is, `testy`) as well as the predicted labels and returns the confusion matrix. The confusion matrix should be a `np.array`.\n",
    "\n",
    "**Note:** Record the cpu time it takes to perform the evaluation on the test set using functions like **time.time()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(testy, testy_fit):\n",
    "    # inputs: the correct labels, the fitted KNN labels \n",
    "    # output: a 10x10 np.array representing the confusion matrix as above\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    n_classes = len(np.unique(testy))  # Get the number of unique classes\n",
    "    confusion_matrix = np.zeros((n_classes, n_classes), dtype=int)\n",
    "\n",
    "    for true_label, predicted_label in zip(testy, testy_fit):\n",
    "        confusion_matrix[true_label][predicted_label] += 1\n",
    "\n",
    "    return confusion_matrix\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test:  0.9302325581395349\n",
      "[[23  6]\n",
      " [ 0 57]]\n",
      "the test time \n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Code for performing the final evaluation on the test set and generating the confuson matrix.\n",
    "### START CODE HERE ###\n",
    "# X_val, X_test, y_val, y_test \n",
    "startTime = time.process_time()\n",
    "y_pred =KNN(X_train, y_train, X_test, 5, dist_metric=1)\n",
    "endTime = time.process_time()\n",
    "print(\"accuracy on test: \", accuracy(y_pred, y_test))\n",
    "allTime = endTime - startTime\n",
    "arr =  confusion(y_test, y_pred)\n",
    "print(arr)\n",
    "print(\"the test time \")\n",
    "print(allTime)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Preparing the assignment report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to record your answers for the following questions:\n",
    "1. What is the error rate on the validation set for NN_L2?\n",
    "1: 0.8941176470588236\n",
    "2. What is the best error rate on the validation set for KNN_L2?\n",
    "3: 0.9411764705882353\n",
    "3. What is the error rate on the validation set for NN_L1?\n",
    "1: 0.9176470588235294\n",
    "4. What is the best error rate on the validation set for KNN_L1?\n",
    "5: 0.9529411764705882\n",
    "5. What is the error rate on the test set?\n",
    "0.9302325581395349\n",
    "7. Do you need to normalize data, in general, when using KNN?\n",
    "ans: depeneds, sometimes so that not a single feature dominate the testing phase, making all the other features irreleavent\n",
    "8. Do you need to normalize data when using KNN for the given problem? Explain why? \n",
    "appearently we don't since the performance is alright, not too bad, not too great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Extra Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are invited to try some more ideas as extra work like:\n",
    "1. Implementing weighted KNN where the vote of a neighbour is scaled down based on its distance from the test point.\n",
    "2. Implement L_infinity distance measure and use it for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points to remember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to keep in mind the following points:\n",
    "1. Use numpy arrays and numpy libraries for efficient computations. \n",
    "2. Vectorize the code wherever possible instead of using explicit loops. This will significantly speed-up your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
